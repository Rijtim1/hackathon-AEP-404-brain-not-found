{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain==0.2.12\n",
    "# !pip install langgraph==0.2.2\n",
    "# !pip install langchain-ollama==0.1.1\n",
    "# !pip install langsmith==0.1.98\n",
    "# !pip install langchain_community==0.2.11\n",
    "# !pip install duckduckgo-search==6.2.13\n",
    "# !pip install pandas\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import string\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3 = ChatOllama(model=\"llama3.2:3b\",\n",
    "                    format=\"json\",\n",
    "                    temperature=0.1,\n",
    "                    top_k=100,\n",
    "                    top_p=0.1,\n",
    "                    seed=seed,\n",
    "                    mirostat_tau=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(question):\n",
    "    return llama3.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm_with_retry(prompt, max_retries=3):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        response = call_llm(prompt)\n",
    "        try:\n",
    "            response_content = response.content\n",
    "            json_response = json.loads(response_content)\n",
    "            return json_response  # Return valid JSON response\n",
    "        except (json.JSONDecodeError, AttributeError) as e:\n",
    "            retries += 1\n",
    "            print(f\"Retry {retries} for prompt due to: {e}\")\n",
    "    return None  # Return None if all retries fail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_call_llm(prompts, batch_size=10):\n",
    "    all_responses = []\n",
    "    for i in range(0, len(prompts), batch_size):\n",
    "        batch_prompts = prompts[i:i + batch_size]\n",
    "        responses = llama3.batch(batch_prompts)  # Use batch call for parallel processing\n",
    "        all_responses.extend([resp.content for resp in responses])\n",
    "    return all_responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIF_KEYWORDS = [\n",
    "    \"suspend\", \"load\", \"fall\", \"elevation\", \"mobile\", \"equipment\", \"traffic\", \"motor\", \"vehicle\", \"heavy\", \n",
    "    \"rotating\", \"equipment\", \"machine\", \"mechanical\", \"temperature\", \"high\", \"steam\", \"fire\", \"fuel\", \n",
    "    \"explosion\", \"trench\", \"excavation\", \"electrical\", \"contact\", \"arc\", \"flash\", \"toxic\", \"chemical\", \n",
    "    \"radiation\", \"high-energy\", \"pressure\", \"unsupported\", \"soil\", \"depth\", \"voltage\", \"shock\", \"burn\", \n",
    "    \"third-degree\", \"burns\", \"combustion\", \"IDLH\", \"oxygen depletion\", \"pH\", \"corrosive\", \"exposure\", \n",
    "    \"crane\", \"hoist\", \"lifting\", \"work zone\", \"pedestrian\", \"struck\", \"vehicle speed\", \"30 mph\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_risk_score(text, keywords=SIF_KEYWORDS):\n",
    "    # Create a regex pattern from the keywords\n",
    "    pattern = re.compile(r'\\b(?:' + '|'.join(re.escape(k) for k in keywords) + r')\\b')\n",
    "    return len(re.findall(pattern, text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = r\"CORE_HackOhio_subset_cleaned_downsampled 1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['RESPONSE'] = None\n",
    "dataframe['HIGH_ENERGY'] = None\n",
    "dataframe['INCIDENT'] = None\n",
    "dataframe['INJURY'] = None\n",
    "dataframe['CONTROLS_PRESENT'] = None\n",
    "dataframe['SEVERITY_SCORE'] = None\n",
    "dataframe['LLM_STATUS'] = None\n",
    "dataframe['CONFIDENCE_SCORE'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "RISK_SCORE = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_responses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assembling Prompts: 100%|██████████| 20000/20000 [00:50<00:00, 397.40row/s]\n"
     ]
    }
   ],
   "source": [
    "# Main loop to process each row and call the LLM\n",
    "for index, row in tqdm(dataframe.iterrows(), desc=\"Assembling Prompts\", total=len(dataframe), unit=\"row\"):\n",
    "    point_name = row['PNT_NM']\n",
    "    qualifier_txt = row['QUALIFIER_TXT']\n",
    "    atrisk_notes = row['PNT_ATRISKNOTES_TX']\n",
    "    followup_notes = row['PNT_ATRISKFOLWUPNTS_TX']\n",
    "\n",
    "    if pd.isna(followup_notes):\n",
    "        followup_notes = \"No follow-up notes provided.\"\n",
    "\n",
    "    combined_text = preprocess_text(f\"{point_name} {qualifier_txt} {atrisk_notes} {followup_notes}\")\n",
    "    risk_score = calculate_risk_score(combined_text)\n",
    "\n",
    "    dataframe.at[index, 'RISK_SCORE'] = risk_score\n",
    "    # dataframe.at[index, 'COMBINED_TEXT'] = combined_text\n",
    "\n",
    "    if risk_score > RISK_SCORE:\n",
    "        prompt = f\"\"\"\n",
    "        Safety Observation: {combined_text}.\n",
    "        Based on the safety observation provided, please answer the following questions by providing a **valid JSON object**. All answers should be in exact field names and integer values only (1 for Yes, 0 for No). Ensure consistency with the safety guidelines provided below.\n",
    "\n",
    "        JSON format:\n",
    "        {{\n",
    "        \"high_energy_present\": 1 or 0, \n",
    "        \"high_energy_incident\": 1 or 0, \n",
    "        \"serious_injury_sustained\": 1 or 0, \n",
    "        \"direct_controls_present\": 1 or 0, \n",
    "        \"severity_score\": 1 to 5, \n",
    "        \"confidence_score\": 0 to 1\n",
    "        }}\n",
    "\n",
    "        ### Guidelines for Responses:\n",
    "        1. **Is high-energy present?** \n",
    "        (High-energy refers to any condition where energy exceeds 500 ft-lbs, such as electrical sources >50 volts, falling from heights >4 feet, mechanical equipment, etc.)\n",
    "        \n",
    "        2. **Was there a high-energy incident?**\n",
    "        (An incident is defined by the release of high energy where a worker was in contact or proximity, within 6 feet without restricted egress.)\n",
    "\n",
    "        3. **Was a serious injury sustained?** \n",
    "        (Serious injuries are life-threatening or life-altering injuries, as defined by EEI criteria: fractures, amputations, concussions, third-degree burns, etc.)\n",
    "\n",
    "        4. **Were direct controls present?** \n",
    "        (Direct controls refer to barriers that specifically mitigate high-energy hazards. Examples include LOTO, fall protection, or machine guarding, not general safety equipment like PPE unless specifically designed to target the high-energy source.)\n",
    "\n",
    "        5. **Provide a severity score** from 1 (low severity) to 5 (high severity). \n",
    "        (Assess the potential severity of the incident based on proximity, injury risk, and energy magnitude.)\n",
    "\n",
    "        6. **Confidence score** (0-1): \n",
    "        Provide a confidence score from 0 (low) to 1 (high), reflecting your certainty in the presence of high-energy, control effectiveness, and the accuracy of this classification.\n",
    "\n",
    "        Ensure the response is clear, concise, and structured as a JSON object.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # Call the LLM with retry logic\n",
    "        response_content = call_llm_with_retry(prompt)\n",
    "        if response_content is None:\n",
    "            print(f\"Error processing prompt for row {index}\")\n",
    "            dataframe.at[index, 'LLM_STATUS'] = \"LLM Failed\"\n",
    "            failed_responses.append({\"index\": index, \"prompt\": prompt, \"error\": \"LLM Error\"})\n",
    "            continue\n",
    "\n",
    "        # Check if response_content is already a dictionary (since JSON is already parsed)\n",
    "        if isinstance(response_content, dict):\n",
    "            json_response = response_content\n",
    "        else:\n",
    "            try:\n",
    "                json_response = json.loads(response_content)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error parsing JSON for row {index}\")\n",
    "                dataframe.at[index, 'LLM_STATUS'] = \"Failed\"\n",
    "                failed_responses.append({\"index\": index, \"prompt\": prompt, \"error\": \"JSON Parsing Error\"})\n",
    "                continue\n",
    "\n",
    "        # Process the JSON response\n",
    "        high_energy = json_response.get(\"high_energy_present\", None)\n",
    "        incident = json_response.get(\"high_energy_incident\", None)\n",
    "        injury = json_response.get(\"serious_injury_sustained\", None)\n",
    "        controls_present = json_response.get(\"direct_controls_present\", None)\n",
    "        severity_score = json_response.get(\"severity_score\", None)\n",
    "        confidence_score = json_response.get(\"confidence_score\", None)\n",
    "\n",
    "        dataframe.at[index, 'HIGH_ENERGY'] = high_energy\n",
    "        dataframe.at[index, 'INCIDENT'] = incident\n",
    "        dataframe.at[index, 'INJURY'] = injury\n",
    "        dataframe.at[index, 'CONTROLS_PRESENT'] = controls_present\n",
    "        dataframe.at[index, 'SEVERITY_SCORE'] = severity_score\n",
    "        dataframe.at[index, 'CONFIDENCE_SCORE'] = confidence_score\n",
    "        dataframe.at[index, 'LLM_STATUS'] = \"Success\"\n",
    "        \n",
    "    # Save progress every 100 rows\n",
    "    if index % 100 == 0:\n",
    "        dataframe.to_csv(f\"output_partial.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. LLM responses saved to output_with_llm_json_responses.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the updated dataframe with numerical responses and status to a new CSV file\n",
    "output_file = \"output_with_llm_json_responses.csv\"\n",
    "dataframe.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processing complete. LLM responses saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"failed_responses.json\", \"w\") as outfile:\n",
    "    json.dump(failed_responses, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. LLM responses saved to output_with_llm_json_responses.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"Processing complete. LLM responses saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
